{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "df7e83ba-34cd-4f9e-8fb5-eb5ec719cf28",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "<span style=\"color:orange\">\n",
    " <h2> Databircks-Assignemnt 5 (Mounting ADLS)\n",
    "</span>\n",
    "  <h5>\n",
    "    <span style=\"color:red\">\n",
    "<b>Author: Deepak Goyal <br>\n",
    "   <a> adeus.azurelib.com </a><br>\n",
    "   Email at: admin@azurelib.com\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "62c53c84-5d19-4115-a775-314575ce42fc",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "<b> Create a ADLS storage account in Azure, or use your existing one. Create a conatiner called 'raw'. Now mount this container into databricks with the mount point '/mnt/azurelib/raw': <br>\n",
    "  Use the SAS Token Mechanism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2d4e6162-dd1d-497a-b403-121b7b3ad8da",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[1]: True"
     ]
    }
   ],
   "source": [
    "# Write your code here\n",
    "dbutils.fs.mount( source = 'wasbs://raw@azurecourse157dl.blob.core.windows.net', \n",
    "                 mount_point= '/mnt/azurelib/raw', extra_configs ={'fs.azure.sas.raw.azurecourse157dl.blob.core.windows.net':'?sv=2022-11-02&ss=bfqt&srt=sco&sp=rwdlacupyx&se=2023-08-24T00:25:48Z&st=2023-08-23T16:25:48Z&spr=https&sig=%2BBpLgixBHPWqaCvVmBkDDOdvqk2A8PcKfCEabIsCobc%3D'})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8364e840-c519-4ac5-a1bf-b9b89b994321",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "<b> Create a ADLS storage account in Azure, or use your existing one. Create a conatiner called 'processed'. Now mount this container into databricks with the mount point '/mnt/azurelib/processed': <br>\n",
    "  Use the App Registration Mechanism (If you active azure subcription do it. Else skip it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a0185598-138a-4fd1-a503-3e1a0c301712",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[2]: True"
     ]
    }
   ],
   "source": [
    "# Write your code\n",
    "configs = {\"fs.azure.account.auth.type\": \"OAuth\",\n",
    "       \"fs.azure.account.oauth.provider.type\": \"org.apache.hadoop.fs.azurebfs.oauth2.ClientCredsTokenProvider\",\n",
    "       \"fs.azure.account.oauth2.client.id\": \"6bc2339d-9b60-41b2-b19c-442cde6de5bc\",\n",
    "       \"fs.azure.account.oauth2.client.secret\": \"ahn8Q~ci0c6KdeoN7ZBb6Exb6tP-irig1c.V6bw0\",\n",
    "       \"fs.azure.account.oauth2.client.endpoint\": \"https://login.microsoftonline.com/e9b0fb24-38ea-4968-a4c7-2c22040dc39b/oauth2/token\",\n",
    "       \"fs.azure.createRemoteFileSystemDuringInitialization\": \"true\"}\n",
    "\n",
    "dbutils.fs.mount(source = \"abfss://processed@azurecourse157dl.dfs.core.windows.net\",mount_point = \"/mnt/azurelib/processed\",extra_configs = configs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "14772c70-beff-49d9-828a-724188863639",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "<b> Create a ADLS storage account in Azure, or use your existing one. Create a conatiner called 'raw_secured'. Now mount this container into databricks with the mount point '/mnt/azurelib/raw_secured':\n",
    "<br>\n",
    "  <br>\n",
    "  Use the SAS Token, Key vault and Secret Scope to create this mount point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5233f351-ed0d-4c5d-8c49-b382053a6e91",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mPy4JJavaError\u001B[0m                             Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-3722441895726167>:5\u001B[0m\n",
       "\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# Write your code using the Spark Function\u001B[39;00m\n",
       "\u001B[1;32m      2\u001B[0m configs \u001B[38;5;241m=\u001B[39m {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfs.azure.account.auth.type\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mOAuth\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n",
       "\u001B[1;32m      3\u001B[0m        \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfs.azure.account.oauth.provider.type\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124morg.apache.hadoop.fs.azurebfs.oauth2.ClientCredsTokenProvider\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n",
       "\u001B[1;32m      4\u001B[0m        \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfs.azure.account.oauth2.client.id\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m6bc2339d-9b60-41b2-b19c-442cde6de5bc\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n",
       "\u001B[0;32m----> 5\u001B[0m        \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfs.azure.account.oauth2.client.secret\u001B[39m\u001B[38;5;124m\"\u001B[39m: dbutils\u001B[38;5;241m.\u001B[39msecrets\u001B[38;5;241m.\u001B[39mget(scope\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124me9b0fb24-38ea-4968-a4c7-2c22040dc39b\u001B[39m\u001B[38;5;124m\"\u001B[39m,key\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDatabricks-Course-Secret-Scope-157\u001B[39m\u001B[38;5;124m\"\u001B[39m),\n",
       "\u001B[1;32m      6\u001B[0m        \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfs.azure.account.oauth2.client.endpoint\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhttps://login.microsoftonline.com/e9b0fb24-38ea-4968-a4c7-2c22040dc39b/oauth2/token\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n",
       "\u001B[1;32m      7\u001B[0m        \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfs.azure.createRemoteFileSystemDuringInitialization\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtrue\u001B[39m\u001B[38;5;124m\"\u001B[39m}\n",
       "\u001B[1;32m      9\u001B[0m dbutils\u001B[38;5;241m.\u001B[39mfs\u001B[38;5;241m.\u001B[39mmount(source \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mabfss://rawsecured@azurecourse157dl.dfs.core.windows.net\u001B[39m\u001B[38;5;124m\"\u001B[39m,mount_point \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m/mnt/azurelib/raw_secured\u001B[39m\u001B[38;5;124m\"\u001B[39m,extra_configs \u001B[38;5;241m=\u001B[39m configs)\n",
       "\n",
       "File \u001B[0;32m/databricks/python_shell/dbruntime/dbutils.py:240\u001B[0m, in \u001B[0;36mDBUtils.SecretsHandler.get\u001B[0;34m(self, scope, key)\u001B[0m\n",
       "\u001B[1;32m    239\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget\u001B[39m(\u001B[38;5;28mself\u001B[39m, scope, key):\n",
       "\u001B[0;32m--> 240\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mentry_point\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgetDbutils\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpreview\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msecret\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[43mscope\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkey\u001B[49m\u001B[43m)\u001B[49m\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py:1321\u001B[0m, in \u001B[0;36mJavaMember.__call__\u001B[0;34m(self, *args)\u001B[0m\n",
       "\u001B[1;32m   1315\u001B[0m command \u001B[38;5;241m=\u001B[39m proto\u001B[38;5;241m.\u001B[39mCALL_COMMAND_NAME \u001B[38;5;241m+\u001B[39m\\\n",
       "\u001B[1;32m   1316\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcommand_header \u001B[38;5;241m+\u001B[39m\\\n",
       "\u001B[1;32m   1317\u001B[0m     args_command \u001B[38;5;241m+\u001B[39m\\\n",
       "\u001B[1;32m   1318\u001B[0m     proto\u001B[38;5;241m.\u001B[39mEND_COMMAND_PART\n",
       "\u001B[1;32m   1320\u001B[0m answer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgateway_client\u001B[38;5;241m.\u001B[39msend_command(command)\n",
       "\u001B[0;32m-> 1321\u001B[0m return_value \u001B[38;5;241m=\u001B[39m \u001B[43mget_return_value\u001B[49m\u001B[43m(\u001B[49m\n",
       "\u001B[1;32m   1322\u001B[0m \u001B[43m    \u001B[49m\u001B[43manswer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgateway_client\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtarget_id\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m   1324\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m temp_arg \u001B[38;5;129;01min\u001B[39;00m temp_args:\n",
       "\u001B[1;32m   1325\u001B[0m     temp_arg\u001B[38;5;241m.\u001B[39m_detach()\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/pyspark/errors/exceptions.py:228\u001B[0m, in \u001B[0;36mcapture_sql_exception.<locals>.deco\u001B[0;34m(*a, **kw)\u001B[0m\n",
       "\u001B[1;32m    226\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdeco\u001B[39m(\u001B[38;5;241m*\u001B[39ma: Any, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkw: Any) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Any:\n",
       "\u001B[1;32m    227\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n",
       "\u001B[0;32m--> 228\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mf\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43ma\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkw\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m    229\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m Py4JJavaError \u001B[38;5;28;01mas\u001B[39;00m e:\n",
       "\u001B[1;32m    230\u001B[0m         converted \u001B[38;5;241m=\u001B[39m convert_exception(e\u001B[38;5;241m.\u001B[39mjava_exception)\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/protocol.py:326\u001B[0m, in \u001B[0;36mget_return_value\u001B[0;34m(answer, gateway_client, target_id, name)\u001B[0m\n",
       "\u001B[1;32m    324\u001B[0m value \u001B[38;5;241m=\u001B[39m OUTPUT_CONVERTER[\u001B[38;5;28mtype\u001B[39m](answer[\u001B[38;5;241m2\u001B[39m:], gateway_client)\n",
       "\u001B[1;32m    325\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m answer[\u001B[38;5;241m1\u001B[39m] \u001B[38;5;241m==\u001B[39m REFERENCE_TYPE:\n",
       "\u001B[0;32m--> 326\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m Py4JJavaError(\n",
       "\u001B[1;32m    327\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAn error occurred while calling \u001B[39m\u001B[38;5;132;01m{0}\u001B[39;00m\u001B[38;5;132;01m{1}\u001B[39;00m\u001B[38;5;132;01m{2}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39m\n",
       "\u001B[1;32m    328\u001B[0m         \u001B[38;5;28mformat\u001B[39m(target_id, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m, name), value)\n",
       "\u001B[1;32m    329\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
       "\u001B[1;32m    330\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m Py4JError(\n",
       "\u001B[1;32m    331\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAn error occurred while calling \u001B[39m\u001B[38;5;132;01m{0}\u001B[39;00m\u001B[38;5;132;01m{1}\u001B[39;00m\u001B[38;5;132;01m{2}\u001B[39;00m\u001B[38;5;124m. Trace:\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m{3}\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39m\n",
       "\u001B[1;32m    332\u001B[0m         \u001B[38;5;28mformat\u001B[39m(target_id, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m, name, value))\n",
       "\n",
       "\u001B[0;31mPy4JJavaError\u001B[0m: An error occurred while calling o442.get.\n",
       ": java.lang.IllegalStateException: Secrets API is not enabled for this workspace.\n",
       "\tat com.databricks.backend.common.rpc.SimpleSecretManagerClient.performRequestReliably(SecretManagerClient.scala:123)\n",
       "\tat com.databricks.backend.common.rpc.SimpleSecretManagerClient.get(SecretManagerClient.scala:157)\n",
       "\tat com.databricks.backend.common.rpc.SimpleSecretManagerClient.getSecret(SecretManagerClient.scala:232)\n",
       "\tat com.databricks.dbutils_v1.impl.SecretUtilsImpl.getBytesInternal(SecretUtilsImpl.scala:46)\n",
       "\tat com.databricks.dbutils_v1.impl.SecretUtilsImpl.get(SecretUtilsImpl.scala:61)\n",
       "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
       "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
       "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
       "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
       "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
       "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:380)\n",
       "\tat py4j.Gateway.invoke(Gateway.java:306)\n",
       "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
       "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
       "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:195)\n",
       "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:115)\n",
       "\tat java.lang.Thread.run(Thread.java:750)\n"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n\u001B[0;31mPy4JJavaError\u001B[0m                             Traceback (most recent call last)\nFile \u001B[0;32m<command-3722441895726167>:5\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# Write your code using the Spark Function\u001B[39;00m\n\u001B[1;32m      2\u001B[0m configs \u001B[38;5;241m=\u001B[39m {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfs.azure.account.auth.type\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mOAuth\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m      3\u001B[0m        \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfs.azure.account.oauth.provider.type\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124morg.apache.hadoop.fs.azurebfs.oauth2.ClientCredsTokenProvider\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m      4\u001B[0m        \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfs.azure.account.oauth2.client.id\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m6bc2339d-9b60-41b2-b19c-442cde6de5bc\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m----> 5\u001B[0m        \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfs.azure.account.oauth2.client.secret\u001B[39m\u001B[38;5;124m\"\u001B[39m: dbutils\u001B[38;5;241m.\u001B[39msecrets\u001B[38;5;241m.\u001B[39mget(scope\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124me9b0fb24-38ea-4968-a4c7-2c22040dc39b\u001B[39m\u001B[38;5;124m\"\u001B[39m,key\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDatabricks-Course-Secret-Scope-157\u001B[39m\u001B[38;5;124m\"\u001B[39m),\n\u001B[1;32m      6\u001B[0m        \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfs.azure.account.oauth2.client.endpoint\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhttps://login.microsoftonline.com/e9b0fb24-38ea-4968-a4c7-2c22040dc39b/oauth2/token\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m      7\u001B[0m        \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfs.azure.createRemoteFileSystemDuringInitialization\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtrue\u001B[39m\u001B[38;5;124m\"\u001B[39m}\n\u001B[1;32m      9\u001B[0m dbutils\u001B[38;5;241m.\u001B[39mfs\u001B[38;5;241m.\u001B[39mmount(source \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mabfss://rawsecured@azurecourse157dl.dfs.core.windows.net\u001B[39m\u001B[38;5;124m\"\u001B[39m,mount_point \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m/mnt/azurelib/raw_secured\u001B[39m\u001B[38;5;124m\"\u001B[39m,extra_configs \u001B[38;5;241m=\u001B[39m configs)\n\nFile \u001B[0;32m/databricks/python_shell/dbruntime/dbutils.py:240\u001B[0m, in \u001B[0;36mDBUtils.SecretsHandler.get\u001B[0;34m(self, scope, key)\u001B[0m\n\u001B[1;32m    239\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget\u001B[39m(\u001B[38;5;28mself\u001B[39m, scope, key):\n\u001B[0;32m--> 240\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mentry_point\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgetDbutils\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpreview\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msecret\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[43mscope\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkey\u001B[49m\u001B[43m)\u001B[49m\n\nFile \u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py:1321\u001B[0m, in \u001B[0;36mJavaMember.__call__\u001B[0;34m(self, *args)\u001B[0m\n\u001B[1;32m   1315\u001B[0m command \u001B[38;5;241m=\u001B[39m proto\u001B[38;5;241m.\u001B[39mCALL_COMMAND_NAME \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1316\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcommand_header \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1317\u001B[0m     args_command \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1318\u001B[0m     proto\u001B[38;5;241m.\u001B[39mEND_COMMAND_PART\n\u001B[1;32m   1320\u001B[0m answer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgateway_client\u001B[38;5;241m.\u001B[39msend_command(command)\n\u001B[0;32m-> 1321\u001B[0m return_value \u001B[38;5;241m=\u001B[39m \u001B[43mget_return_value\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1322\u001B[0m \u001B[43m    \u001B[49m\u001B[43manswer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgateway_client\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtarget_id\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1324\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m temp_arg \u001B[38;5;129;01min\u001B[39;00m temp_args:\n\u001B[1;32m   1325\u001B[0m     temp_arg\u001B[38;5;241m.\u001B[39m_detach()\n\nFile \u001B[0;32m/databricks/spark/python/pyspark/errors/exceptions.py:228\u001B[0m, in \u001B[0;36mcapture_sql_exception.<locals>.deco\u001B[0;34m(*a, **kw)\u001B[0m\n\u001B[1;32m    226\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdeco\u001B[39m(\u001B[38;5;241m*\u001B[39ma: Any, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkw: Any) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Any:\n\u001B[1;32m    227\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 228\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mf\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43ma\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkw\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    229\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m Py4JJavaError \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    230\u001B[0m         converted \u001B[38;5;241m=\u001B[39m convert_exception(e\u001B[38;5;241m.\u001B[39mjava_exception)\n\nFile \u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/protocol.py:326\u001B[0m, in \u001B[0;36mget_return_value\u001B[0;34m(answer, gateway_client, target_id, name)\u001B[0m\n\u001B[1;32m    324\u001B[0m value \u001B[38;5;241m=\u001B[39m OUTPUT_CONVERTER[\u001B[38;5;28mtype\u001B[39m](answer[\u001B[38;5;241m2\u001B[39m:], gateway_client)\n\u001B[1;32m    325\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m answer[\u001B[38;5;241m1\u001B[39m] \u001B[38;5;241m==\u001B[39m REFERENCE_TYPE:\n\u001B[0;32m--> 326\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m Py4JJavaError(\n\u001B[1;32m    327\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAn error occurred while calling \u001B[39m\u001B[38;5;132;01m{0}\u001B[39;00m\u001B[38;5;132;01m{1}\u001B[39;00m\u001B[38;5;132;01m{2}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39m\n\u001B[1;32m    328\u001B[0m         \u001B[38;5;28mformat\u001B[39m(target_id, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m, name), value)\n\u001B[1;32m    329\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    330\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m Py4JError(\n\u001B[1;32m    331\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAn error occurred while calling \u001B[39m\u001B[38;5;132;01m{0}\u001B[39;00m\u001B[38;5;132;01m{1}\u001B[39;00m\u001B[38;5;132;01m{2}\u001B[39;00m\u001B[38;5;124m. Trace:\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m{3}\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39m\n\u001B[1;32m    332\u001B[0m         \u001B[38;5;28mformat\u001B[39m(target_id, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m, name, value))\n\n\u001B[0;31mPy4JJavaError\u001B[0m: An error occurred while calling o442.get.\n: java.lang.IllegalStateException: Secrets API is not enabled for this workspace.\n\tat com.databricks.backend.common.rpc.SimpleSecretManagerClient.performRequestReliably(SecretManagerClient.scala:123)\n\tat com.databricks.backend.common.rpc.SimpleSecretManagerClient.get(SecretManagerClient.scala:157)\n\tat com.databricks.backend.common.rpc.SimpleSecretManagerClient.getSecret(SecretManagerClient.scala:232)\n\tat com.databricks.dbutils_v1.impl.SecretUtilsImpl.getBytesInternal(SecretUtilsImpl.scala:46)\n\tat com.databricks.dbutils_v1.impl.SecretUtilsImpl.get(SecretUtilsImpl.scala:61)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:380)\n\tat py4j.Gateway.invoke(Gateway.java:306)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:195)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:115)\n\tat java.lang.Thread.run(Thread.java:750)\n",
       "errorSummary": "java.lang.IllegalStateException: Secrets API is not enabled for this workspace.",
       "errorTraceType": "ansi",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Write your code using the Spark Function\n",
    "configs = {\"fs.azure.account.auth.type\": \"OAuth\",\n",
    "       \"fs.azure.account.oauth.provider.type\": \"org.apache.hadoop.fs.azurebfs.oauth2.ClientCredsTokenProvider\",\n",
    "       \"fs.azure.account.oauth2.client.id\": \"6bc2339d-9b60-41b2-b19c-442cde6de5bc\",\n",
    "       \"fs.azure.account.oauth2.client.secret\": dbutils.secrets.get(scope=\"e9b0fb24-38ea-4968-a4c7-2c22040dc39b\",key=\"Databricks-Course-Secret-Scope-157\"),\n",
    "       \"fs.azure.account.oauth2.client.endpoint\": \"https://login.microsoftonline.com/e9b0fb24-38ea-4968-a4c7-2c22040dc39b/oauth2/token\",\n",
    "       \"fs.azure.createRemoteFileSystemDuringInitialization\": \"true\"}\n",
    "\n",
    "dbutils.fs.mount(source = \"abfss://rawsecured@azurecourse157dl.dfs.core.windows.net\",mount_point = \"/mnt/azurelib/raw_secured\",extra_configs = configs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "88ce7a13-79be-40fc-8a54-359bdf9c7fff",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[5]: Row(id='1', first_name='Valene', last_name='Ingley', email='vingley0@livejournal.com', gender='Female', salary='44104', creationDate='1957-09-09 16:44:40', bonus=None)"
     ]
    }
   ],
   "source": [
    "df = spark.read.csv(\"/mnt/azurelib/raw/EmployeeData.csv\",header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "be44eadd-50ea-440a-b1ba-38ed02750b10",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+---------+--------------------+------+------+-------------------+--------+\n| id|first_name|last_name|               email|gender|salary|       creationDate|   bonus|\n+---+----------+---------+--------------------+------+------+-------------------+--------+\n|  1|    Valene|   Ingley|vingley0@livejour...|Female| 44104|1957-09-09 16:44:40|    null|\n|  2|  Lynnelle|    Hurll| lhurll1@answers.com|Female|112411|1907-05-10 17:38:56|    null|\n|  3|   Miranda|    Train|   mtrain2@imgur.com|Female| 91073|1941-01-24 16:05:23|12875.54|\n|  4|    Dulsea|     Foss|dfoss3@dagondesig...|Female|193291|1942-05-09 20:59:39|    null|\n|  5|    Anatol|  Dunklee| adunklee4@google.de|  Male| 22175|1950-07-26 16:28:00| 1432.12|\n|  6|     Baily|   Antony| bantony5@sfgate.com|  Male|127337|1913-10-14 11:25:33|    null|\n|  7|    Eunice|   Cardus|ecardus6@scientif...|Female|136574|1901-11-02 15:09:47|38676.94|\n|  8|  Aubrette|  Lippett| alippett7@nifty.com|Female|165713|1919-12-16 08:20:42|60150.66|\n|  9|   Sibylla|Sickamore|ssickamore8@faceb...|Female|107243|2020-03-15 15:00:30|    null|\n| 10|      null|   Altree|paltree9@dropbox.com|Female|197594|1975-06-21 23:27:12|72533.37|\n| 11|      Coop|    Richt|   crichta@sogou.com|  Male| 19964|1939-02-13 16:18:24|56973.41|\n| 12|  Giuseppe|  Scimoni|gscimonib@craigsl...|  Male|176531|1967-04-06 07:23:03|    null|\n| 13|    Lovell|  Iorizzo|liorizzoc@cpanel.net|  Male|189150|1949-06-06 16:25:20| 41474.8|\n| 14|       Deb|    Mogra|   dmograd@bbc.co.uk|Female|197829|1997-07-27 14:55:52|46528.57|\n| 15|  Hastings| Jelliman|hjellimane@histat...|  Male|179296|1915-07-05 07:02:06|80194.64|\n| 16|     Josee|   Burnep|    jburnepf@php.net|  null| 78569|1923-11-08 20:59:14|88925.13|\n| 17|     Gilly|   Fownes|gfownesg@redcross...|Female|  2527|1946-07-30 21:10:57|    null|\n| 18|      null|Schruyers|lschruyersh@desde...|  Male|109936|1979-06-16 01:12:48|37243.09|\n| 19|     Maris|Chatelain| mchatelaini@unc.edu|Female|190047|2008-01-11 17:16:21|76469.65|\n| 20|    Casper|  Aughtie|    caughtiej@vk.com|  Male| 38689|1982-04-06 05:13:49| 80404.8|\n+---+----------+---------+--------------------+------+------+-------------------+--------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cae0fe03-6339-4dac-9a18-1a5a1da78612",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "d\n",
    "<b> Are there any employees with negative salary or bonus amounts in the input file? If so, how many?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0bf0728d-c9ff-4d5f-9cb4-00d7a34bb988",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+---------+--------------------+------+------+-------------------+--------+\n| id|first_name|last_name|               email|gender|salary|       creationDate|   bonus|\n+---+----------+---------+--------------------+------+------+-------------------+--------+\n|  1|    Valene|   Ingley|vingley0@livejour...|Female| 44104|1957-09-09 16:44:40|    null|\n|  2|  Lynnelle|    Hurll| lhurll1@answers.com|Female|112411|1907-05-10 17:38:56|    null|\n|  3|   Miranda|    Train|   mtrain2@imgur.com|Female| 91073|1941-01-24 16:05:23|12875.54|\n|  4|    Dulsea|     Foss|dfoss3@dagondesig...|Female|193291|1942-05-09 20:59:39|    null|\n|  5|    Anatol|  Dunklee| adunklee4@google.de|  Male| 22175|1950-07-26 16:28:00| 1432.12|\n|  6|     Baily|   Antony| bantony5@sfgate.com|  Male|127337|1913-10-14 11:25:33|    null|\n|  7|    Eunice|   Cardus|ecardus6@scientif...|Female|136574|1901-11-02 15:09:47|38676.94|\n|  8|  Aubrette|  Lippett| alippett7@nifty.com|Female|165713|1919-12-16 08:20:42|60150.66|\n|  9|   Sibylla|Sickamore|ssickamore8@faceb...|Female|107243|2020-03-15 15:00:30|    null|\n| 10|      null|   Altree|paltree9@dropbox.com|Female|197594|1975-06-21 23:27:12|72533.37|\n| 11|      Coop|    Richt|   crichta@sogou.com|  Male| 19964|1939-02-13 16:18:24|56973.41|\n| 12|  Giuseppe|  Scimoni|gscimonib@craigsl...|  Male|176531|1967-04-06 07:23:03|    null|\n| 13|    Lovell|  Iorizzo|liorizzoc@cpanel.net|  Male|189150|1949-06-06 16:25:20| 41474.8|\n| 14|       Deb|    Mogra|   dmograd@bbc.co.uk|Female|197829|1997-07-27 14:55:52|46528.57|\n| 15|  Hastings| Jelliman|hjellimane@histat...|  Male|179296|1915-07-05 07:02:06|80194.64|\n| 16|     Josee|   Burnep|    jburnepf@php.net|  null| 78569|1923-11-08 20:59:14|88925.13|\n| 17|     Gilly|   Fownes|gfownesg@redcross...|Female|  2527|1946-07-30 21:10:57|    null|\n| 18|      null|Schruyers|lschruyersh@desde...|  Male|109936|1979-06-16 01:12:48|37243.09|\n| 19|     Maris|Chatelain| mchatelaini@unc.edu|Female|190047|2008-01-11 17:16:21|76469.65|\n| 20|    Casper|  Aughtie|    caughtiej@vk.com|  Male| 38689|1982-04-06 05:13:49| 80404.8|\n+---+----------+---------+--------------------+------+------+-------------------+--------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "# Write your code here\n",
    "df.filter(\"salary < 0 or bonus < 0\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8e58642b-6aff-4351-92a0-cea48bfdc948",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "d\n",
    "<b> Display all the mounts point available in your databricks workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4288320d-f41e-4719-99a6-93fe790beacb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>mountPoint</th><th>source</th><th>encryptionType</th></tr></thead><tbody><tr><td>/databricks-datasets</td><td>databricks-datasets</td><td>sse-s3</td></tr><tr><td>/mnt/azurelib/processed</td><td>abfss://processed@azurecourse157dl.dfs.core.windows.net</td><td></td></tr><tr><td>/databricks/mlflow-tracking</td><td>databricks/mlflow-tracking</td><td>sse-s3</td></tr><tr><td>/databricks-results</td><td>databricks-results</td><td>sse-s3</td></tr><tr><td>/databricks/mlflow-registry</td><td>databricks/mlflow-registry</td><td>sse-s3</td></tr><tr><td>/mnt/azurelib/raw</td><td>wasbs://raw@azurecourse157dl.blob.core.windows.net</td><td></td></tr><tr><td>/</td><td>DatabricksRoot</td><td>sse-s3</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "/databricks-datasets",
         "databricks-datasets",
         "sse-s3"
        ],
        [
         "/mnt/azurelib/processed",
         "abfss://processed@azurecourse157dl.dfs.core.windows.net",
         ""
        ],
        [
         "/databricks/mlflow-tracking",
         "databricks/mlflow-tracking",
         "sse-s3"
        ],
        [
         "/databricks-results",
         "databricks-results",
         "sse-s3"
        ],
        [
         "/databricks/mlflow-registry",
         "databricks/mlflow-registry",
         "sse-s3"
        ],
        [
         "/mnt/azurelib/raw",
         "wasbs://raw@azurecourse157dl.blob.core.windows.net",
         ""
        ],
        [
         "/",
         "DatabricksRoot",
         "sse-s3"
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "mountPoint",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "source",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "encryptionType",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Write your code here\n",
    "display(dbutils.fs.mounts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d39815e9-f12a-497e-a658-fc9f1c98d271",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "<b> Remove the mount point '/mnt/azurelib/raw_secured'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c1035982-814b-43ff-b9df-55e89c658f68",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Write your code here\n",
    "dbutils.fs.unmount(\"/mnt/azurelib/raw_secured\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "Databircks-Assignemnt5 (Mounting ADLS)",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
